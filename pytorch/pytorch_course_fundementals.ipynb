{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AJZx5t1Z-9oN",
        "outputId": "77ab1ed2-f553-4887-cf8f-db14abfd8f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Creating tensors and the datatype is by default float32 </h2>"
      ],
      "metadata": {
        "id": "MgTLdYHnCPpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scalaer\n",
        "scaler = torch.tensor(7)# you may have a var name \"a\" for scaler\n",
        "print(scaler)\n",
        "print(scaler.ndim) # number of dimentions\n",
        "print(scaler.item())\n",
        "\n",
        "# Vectors: vectors have magnitude (how far it is going) and a direction\n",
        "vector = torch.tensor([7, 7, 7])# you may have a var name \"y\" for vector\n",
        "print('-'*40)\n",
        "print(vector)\n",
        "print(vector.ndim)\n",
        "print(vector.shape)\n",
        "\n",
        "# MATRIX\n",
        "matrix = torch.tensor([[7, 8], [9, 10], [5, 6], [3, 4]])# you may have a var name \"Q\" for matrix\n",
        "print('-'*40)\n",
        "print(matrix)\n",
        "print(matrix.ndim)# 2\n",
        "print(matrix.shape)# torch.Size([4, 2])\n",
        "\n",
        "# TENSOR\n",
        "my_tensor = torch.tensor([\n",
        "    [[1, 2], [3, 4]],\n",
        "     [[5, 6], [7, 8]],\n",
        "      [[9, 10], [11, 12]]\n",
        "    ])# you may have var name \"X\" for the tensor\n",
        "print('-'*40)\n",
        "print(my_tensor)\n",
        "print(my_tensor.ndim)# 3\n",
        "print(my_tensor.shape)# torch.Size([3, 2, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niaysvAuAV7I",
        "outputId": "30c70ba0-9822-4a81-b39f-a5580572e95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7)\n",
            "0\n",
            "7\n",
            "----------------------------------------\n",
            "tensor([7, 7, 7])\n",
            "1\n",
            "torch.Size([3])\n",
            "----------------------------------------\n",
            "tensor([[ 7,  8],\n",
            "        [ 9, 10],\n",
            "        [ 5,  6],\n",
            "        [ 3,  4]])\n",
            "2\n",
            "torch.Size([4, 2])\n",
            "----------------------------------------\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4]],\n",
            "\n",
            "        [[ 5,  6],\n",
            "         [ 7,  8]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [11, 12]]])\n",
            "3\n",
            "torch.Size([3, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random tensors\n",
        "# NNs are learning firstly through tensors of random numbers and then adjust those random numbers to represent the data\n",
        "random_tensor = torch.rand(3, 4) # enter the size of the tensor\n",
        "print(random_tensor)\n",
        "print(random_tensor.ndim)\n",
        "\n",
        "random_image_tensor = torch.rand(size=(224, 224, 3))# (height, width, color channels)\n",
        "# print(random_image_tensor)\n",
        "\n",
        "# Zeros and ones tensor\n",
        "zero = torch.zeros(size=(4,3))\n",
        "print(zero)\n",
        "ones = torch.ones(size=(3, 4))\n",
        "print(ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17W6ltWzwJ5U",
        "outputId": "063ada07-f030-4388-ce29-39272aa01c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7171, 0.8712, 0.1213, 0.0786],\n",
            "        [0.4603, 0.1943, 0.0014, 0.2755],\n",
            "        [0.0277, 0.1405, 0.3362, 0.5322]])\n",
            "2\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Creating a range of tensors </h2>\n",
        "makes a list of numbers from the first param to the end-1 and the 3rd param is the step"
      ],
      "metadata": {
        "id": "0YS1AARwRlS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a torch range\n",
        "one_to_ten = torch.arange(start=0, end=11, step=2)\n",
        "print(one_to_ten)\n",
        "\n",
        "# tensors like\n",
        "# if you want to create a tensor that has the same shape as another tensor\n",
        "ten_zeros = torch.zeros_like(one_to_ten)\n",
        "print(ten_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az-P3-5EPdha",
        "outputId": "f1f2d671-5fd0-46dc-f8bd-aef83a97f7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  2,  4,  6,  8, 10])\n",
            "tensor([0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Datatypes</h2>\n",
        "first of all the datatypes are by default float32"
      ],
      "metadata": {
        "id": "uNrk-AwoVprK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float32, # tensor datatype\n",
        "                               device=None, # tensor device (gpu, cpu, tpu), default: cpu\n",
        "                               requires_grad= False # if you want pytorch to track the gradients\n",
        "                               )\n",
        "print(float_32_tensor)\n",
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "print(float_16_tensor)\n",
        "\n",
        "float_16_tensor * float_32_tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iorxNbDWV2q_",
        "outputId": "5af30dd4-b52e-4c25-9c8f-01a9013b91d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 9.])\n",
            "tensor([3., 6., 9.], dtype=torch.float16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manpulating tensors\n",
        "\n",
        "#### There is 2 ways to preform multiplications in NN and deep learning\n",
        "\n",
        "  1. Element-wise multiplication (multiply num with a matrix)  <code>tensor * num</code>\n",
        "  2. Matrix multiplication (multiplying 2 matrixes with each other)\n",
        "\n",
        "Note: when you multiply 2 matrixes they are multiplied by dot product not normal times e.g. (1,2,3) . (4,5,6) = 1x4 + 2x5 + 3x6"
      ],
      "metadata": {
        "id": "vDUdYk7Oc5RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise Multiplication\n",
        "new_tensor1 = torch.tensor([1, 2, 3])\n",
        "new_tensor2 = torch.tensor([1, 2, 3])\n",
        "new_tensor = torch.tensor([1, 2, 3])\n",
        "print(new_tensor)\n",
        "new_tensor + 10 # add 10 to all values\n",
        "new_tensor * 10 # *10 to all\n",
        "# but it will not reasing it to do so make\n",
        "new_tensor = new_tensor + 10\n",
        "print(new_tensor)\n",
        "\n",
        "print('-'*30)\n",
        "# matrix multiplicatino\n",
        "print(f\"{new_tensor2} (dot multiply) {new_tensor1}\")\n",
        "print(f\"Result: {torch.matmul(new_tensor2, new_tensor1)}\")# 1x1 + 2x2 + 3x3\n",
        "\n",
        "# inner dimentions must match\n",
        "# print(torch.matmul(torch.rand(2, 3), torch.rand(2, 3))) # will not work bec the inner dimention does not match\n",
        "print(torch.matmul(torch.rand(2, 3), torch.rand(3, 2)))\n",
        "print(torch.matmul(torch.rand(4, 2), torch.rand(2, 3)))\n",
        "# the result takes the shape of the outer dimentions\n",
        "# https://matrixmultiplication.xyz/\n",
        "\n",
        "# to fix out the tensor shape issue we can manipulate the shape of one of the tensors, so:\n",
        "print('-'*30)\n",
        "new_tensor3 = torch.tensor([[1, 2],\n",
        "                            [4, 5],\n",
        "                            [7, 8]])\n",
        "print(new_tensor3)\n",
        "print(new_tensor3.T )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNQHYlR-Wrsl",
        "outputId": "7a8da143-c996-4033-f4ae-c5a5631d9a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([11, 12, 13])\n",
            "------------------------------\n",
            "tensor([1, 2, 3]) (dot multiply) tensor([1, 2, 3])\n",
            "Result: 14\n",
            "tensor([[1.1653, 0.9348],\n",
            "        [0.8690, 0.6059]])\n",
            "tensor([[0.3603, 0.1514, 0.2193],\n",
            "        [0.2497, 0.1138, 0.1759],\n",
            "        [1.0485, 0.4823, 0.7512],\n",
            "        [0.7011, 0.3359, 0.5386]])\n",
            "------------------------------\n",
            "tensor([[1, 2],\n",
            "        [4, 5],\n",
            "        [7, 8]])\n",
            "tensor([[1, 4, 7],\n",
            "        [2, 5, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>anything thing you write here you can write it as for example <code>torch.min(my_tens1)</code></h5>"
      ],
      "metadata": {
        "id": "TDKEC3hzRK3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tens1 = torch.rand(12, 12, 3)\n",
        "my_tens2 = torch.rand(12, 12, 3)\n",
        "print(my_tens1.min())\n",
        "print(my_tens1.max())\n",
        "print(my_tens1.type(torch.float32).mean())\n",
        "print(my_tens1.sum())\n",
        "# to get the position (like index) of the min and max\n",
        "print(my_tens1.argmin())\n",
        "print(my_tens1.argmax())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pDZl9udPpsb",
        "outputId": "4f6c6e05-37c6-4e44-e1f6-4241882c545e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0018)\n",
            "tensor(0.9980)\n",
            "tensor(0.4789)\n",
            "tensor(206.8730)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape\n",
        "- It has to be compatible with the original size\n",
        "- Changes the size (shape) of the tensor\n",
        "### View\n",
        "- it is just like reshape\n",
        "- the difference is the new view shares the memory with the original tensor ex:\n",
        "<code>viewed_tens = my_tens.view(3, 12, 12)</code> here the \"viewed_tens\" will share the same memory with the \"my_tens\". <strong>In other words,</strong> changing my_tens will change viewd_tens and vise versa\n",
        "### Stacking\n",
        "- see the example\n",
        "### Squeeze and Unsqueeze\n",
        "- removes all single dimentions from a tensor see the exmaple to understand\n",
        "- unsqueeze makes that extra dimention\n",
        "### permute\n",
        "- rearranges the dimentions of a tensor in a specified order\n",
        "- it is a view that means that it shares the same memory as the originial tensor"
      ],
      "metadata": {
        "id": "gIKDu-eDVXKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tens = torch.rand(12, 12, 3)\n",
        "\n",
        "\n",
        "reshaped_tens = my_tens.reshape(3, 12, 12)\n",
        "# print(reshaped_tens)\n",
        "\n",
        "viewed_tens = my_tens.view(3, 12, 12)\n",
        "\n",
        "x = torch.tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
        "stacked_tens = torch.stack([x, x, x, x], dim=1)\n",
        "print(stacked_tens)\n",
        "print(stacked_tens.shape)\n",
        "print('-'*50)\n",
        "\n",
        "squeezed = stacked_tens.squeeze()\n",
        "print(squeezed)\n",
        "print(f\"before squeezing => {stacked_tens.shape}\")\n",
        "print(f\"squeezed => {squeezed.shape}\")\n",
        "# the dimentions are where the extra dim where be so 0 it will be at the begin 2 at the second and so on\n",
        "unsqueezed = squeezed.unsqueeze(dim=0)\n",
        "print(f\"unsqueezed => {unsqueezed.shape}\")\n",
        "\n",
        "# permute\n",
        "my_tens = torch.rand(224, 224, 3) # 0.height, 1.width, 2.color channels\n",
        "permuted = my_tens.permute(2, 0, 1)\n",
        "print('-'*50)\n",
        "print(f\"permuted {permuted.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sh2hXGKRpxD",
        "outputId": "2d53c80d-2781-4f0e-8740-411852775103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "         [1., 2., 3., 4., 5., 6., 7., 8., 9.]]])\n",
            "torch.Size([1, 4, 9])\n",
            "--------------------------------------------------\n",
            "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "before squeezing => torch.Size([1, 4, 9])\n",
            "squeezed => torch.Size([4, 9])\n",
            "unsqueezed => torch.Size([1, 4, 9])\n",
            "--------------------------------------------------\n",
            "permuted torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing"
      ],
      "metadata": {
        "id": "L8x582xuy9jS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n3X5NO_3Wf8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tens = torch.arange(0,9).reshape(1,3,3)\n",
        "print(f\"{tens} the tens\")\n",
        "print(f\"{tens[0]} index 0\")\n",
        "print(f\"{tens[0][0]} index 0 0\")\n",
        "print(f\"{tens[0][0][0]} index 0 0 0\")\n",
        "print(\"-\"*50)\n",
        "print(f\"{tens[:, :, 1]}\")# get all vals of zero's and first dimentions but only index 1 of the second"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apYWf4Cey8jW",
        "outputId": "d99237cd-fb01-493d-aae2-b117d28349c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]]) the tens\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]]) index 0\n",
            "tensor([0, 1, 2]) index 0 0\n",
            "0 index 0 0 0\n",
            "--------------------------------------------------\n",
            "tensor([[1, 4, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pytorch with numpy\n",
        "- when converting numpy arr to tensor it get a defult of type float64 bec the def type of a numpy arr is float64 unless specified otherwise"
      ],
      "metadata": {
        "id": "1xN5uBjc3ajq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy -> tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "arange_arr = np.arange(1.0, 10.0)\n",
        "tens = torch.from_numpy(arange_arr)\n",
        "print(tens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SBkANe63ZIr",
        "outputId": "816b1947-a22b-4848-c00b-d72d896faa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reproducibility\n",
        "A NN work as follows\n",
        "- start with random numbers\n",
        "- tensor operations\n",
        "- update random numbers to represent the data better and again again again\n",
        "\n",
        "to reduce the randomnise of a random tensor comes the concept of **random seed**. So, for example if you have a random tens every time you run the cell it will be different numbers to avoid that make **seed**, so what a **random seed** makes is \"flavouring\" the randomness"
      ],
      "metadata": {
        "id": "5KHJmd2l6zVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tens1 = torch.rand(3, 4)\n",
        "tens2 = torch.rand(3, 4)\n",
        "\n",
        "print(tens1)\n",
        "print(tens2)\n",
        "print(tens2 == tens1)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# set a random seed\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tens3 = torch.rand(3, 4)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tens4 = torch.rand(3, 4)\n",
        "\n",
        "print(tens3)\n",
        "print(tens4)\n",
        "print(tens3 == tens4)\n",
        "print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd9tU-S47MpA",
        "outputId": "f2731329-969e-4a16-8099-8813c80eb0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
            "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
            "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
            "tensor([[0.5779, 0.9040, 0.5547, 0.3423],\n",
            "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
            "        [0.7890, 0.2814, 0.7886, 0.5895]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n",
            "--------------------------------------------------\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Running on GPU\n",
        "to make that go to the runtime above and click change runtime type and select the gpu"
      ],
      "metadata": {
        "id": "XM2oBPaL_Xod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checks your GPU (Tesla T4)\n",
        "# !nvidia-smi\n",
        "# check for GPU access with Pytorch\n",
        "torch.cuda.is_available()\n",
        "# setup device agnostic code (use the GPU if available if not use CPU normaly)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "# count the number of GPUs\n",
        "torch.cuda.device_count() # 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9jbHzo_eyl",
        "outputId": "192359a9-f007-48cb-a126-5a79b03bc7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Puting tensors and models on the GPU"
      ],
      "metadata": {
        "id": "IgydN8n5Cond"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tens = torch.tensor([1, 2, 3], device=\"cpu\")\n",
        "print(tens, tens.device)\n",
        "\n",
        "# move tens to GPU if available\n",
        "tens_on_gpu = tens.to(device)\n",
        "print(tens_on_gpu)\n",
        "\n",
        "# if tens is on the GPU you can't convert it to Numpy so that's how you rechange it back to the CPU\n",
        "tens_on_cpu = tens_on_gpu.cpu().numpy()\n",
        "print(tens_on_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5HrlyiEC6eG",
        "outputId": "b637580d-5db2-4faf-f425-30d55f6c6577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3], device='cuda:0')\n",
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   torch.manual_seed(42)\n",
        "tens = torch.rand(size=(7, 7))\n",
        "torch.manual_seed(42)\n",
        "tens1 = torch.rand(size=(1, 7))\n",
        "\n",
        "print(tens)\n",
        "print(tens1)\n",
        "\n",
        "print(torch.matmul(tens, tens1.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNGC5hdrHH9C",
        "outputId": "989ce6f4-d20c-4a8a-b98d-d8d5745900d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566],\n",
            "        [0.7936, 0.9408, 0.1332, 0.9346, 0.5936, 0.8694, 0.5677],\n",
            "        [0.7411, 0.4294, 0.8854, 0.5739, 0.2666, 0.6274, 0.2696],\n",
            "        [0.4414, 0.2969, 0.8317, 0.1053, 0.2695, 0.3588, 0.1994],\n",
            "        [0.5472, 0.0062, 0.9516, 0.0753, 0.8860, 0.5832, 0.3376],\n",
            "        [0.8090, 0.5779, 0.9040, 0.5547, 0.3423, 0.6343, 0.3644],\n",
            "        [0.7104, 0.9464, 0.7890, 0.2814, 0.7886, 0.5895, 0.7539]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566]])\n",
            "tensor([[3.2618],\n",
            "        [3.4084],\n",
            "        [2.4866],\n",
            "        [1.4525],\n",
            "        [1.7079],\n",
            "        [2.7291],\n",
            "        [2.9204]])\n"
          ]
        }
      ]
    }
  ]
}